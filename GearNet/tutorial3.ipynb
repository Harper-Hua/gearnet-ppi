{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /Users/harper.h/Documents/cs224w/final_project/yeast_alphafold/UP000002311_559292_YEAST_v2_0.pkl.gz: 100%|██████████| 6026/6026 [00:22<00:00, 263.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchdrug import transforms, datasets\n",
    "import torch\n",
    "\n",
    "truncate_transform = transforms.TruncateProtein(max_length=350, random=False)\n",
    "protein_view_transform = transforms.ProteinView(view=\"residue\")\n",
    "transform = transforms.Compose([truncate_transform, protein_view_transform])\n",
    "\n",
    "dataset = datasets.AlphaFoldDB(path = '/Users/harper.h/Documents/cs224w/final_project/yeast_alphafold', transform=transform, atom_feature=None, \n",
    "                            bond_feature=None)\n",
    "lengths = [int(0.8 * len(dataset)), int(0.1 * len(dataset))]\n",
    "lengths += [len(dataset) - sum(lengths)]\n",
    "train_set, valid_set, test_set = torch.utils.data.random_split(dataset, lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlphaFoldDB(\n",
       "  #sample: 6026\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4820"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AlphaFoldDB' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/harper.h/Documents/cs224w/final_project/GearNet/tutorial3.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/harper.h/Documents/cs224w/final_project/GearNet/tutorial3.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_set, valid_set, test_set \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49msplit()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AlphaFoldDB' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "train_set, valid_set, test_set = dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug import transforms\n",
    "\n",
    "truncate_transform = transforms.TruncateProtein(max_length=350, random=False)\n",
    "protein_view_transform = transforms.ProteinView(view=\"residue\")\n",
    "transform = transforms.Compose([truncate_transform, protein_view_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug import datasets\n",
    "\n",
    "class EnzymeCommissionToy(datasets.EnzymeCommission):\n",
    "    url = \"https://miladeepgraphlearningproteindata.s3.us-east-2.amazonaws.com/data/EnzymeCommission.tar.gz\"\n",
    "    md5 = \"728e0625d1eb513fa9b7626e4d3bcf4d\"\n",
    "    processed_file = \"enzyme_commission_toy.pkl.gz\"\n",
    "    test_cutoffs = [0.3, 0.4, 0.5, 0.7, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:37:48   Extracting /Users/harper.h/protein-datasets/EnzymeCommission.tar.gz to /Users/harper.h/protein-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /Users/harper.h/protein-datasets/EnzymeCommission/enzyme_commission_toy.pkl.gz: 100%|██████████| 1169/1169 [00:01<00:00, 655.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of first instantiation:  2.1469919681549072\n",
      "00:37:50   Extracting /Users/harper.h/protein-datasets/EnzymeCommission.tar.gz to /Users/harper.h/protein-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /Users/harper.h/protein-datasets/EnzymeCommission/enzyme_commission_toy.pkl.gz: 100%|██████████| 1169/1169 [00:01<00:00, 622.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of second instantiation:  2.274559259414673\n",
      "Shape of function labels for a protein:  torch.Size([538])\n",
      "train samples: 974, valid samples: 97, test samples: 98\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "dataset = EnzymeCommissionToy(\"~/protein-datasets/\", transform=transform, atom_feature=None, \n",
    "                            bond_feature=None)\n",
    "end_time = time.time()\n",
    "print(\"Duration of first instantiation: \", end_time - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "dataset = EnzymeCommissionToy(\"~/protein-datasets/\", transform=transform, atom_feature=None, \n",
    "                            bond_feature=None)\n",
    "end_time = time.time()\n",
    "print(\"Duration of second instantiation: \", end_time - start_time)\n",
    "\n",
    "train_set, valid_set, test_set = dataset.split()\n",
    "print(\"Shape of function labels for a protein: \", dataset[0][\"targets\"].shape)\n",
    "print(\"train samples: %d, valid samples: %d, test samples: %d\" % (len(train_set), len(valid_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harper.h/Documents/cs224w/project/.conda/lib/python3.10/site-packages/torchdrug/data/molecule.py:586: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    }
   ],
   "source": [
    "from torchdrug import data\n",
    "\n",
    "protein = dataset[0][\"graph\"]\n",
    "is_first_two = (protein.residue_number == 1) | (protein.residue_number == 2)\n",
    "first_two = protein.residue_mask(is_first_two, compact=True)\n",
    "first_two.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph before:  PackedProtein(batch_size=1, num_atoms=[2639], num_bonds=[5368], num_residues=[350])\n",
      "Graph after:  PackedProtein(batch_size=1, num_atoms=[350], num_bonds=[0], num_residues=[350])\n"
     ]
    }
   ],
   "source": [
    "from torchdrug import layers\n",
    "from torchdrug.layers import geometry\n",
    "\n",
    "graph_construction_model = layers.GraphConstruction(node_layers=[geometry.AlphaCarbonNode()])\n",
    "\n",
    "_protein = data.Protein.pack([protein])\n",
    "protein_ = graph_construction_model(_protein)\n",
    "print(\"Graph before: \", _protein)\n",
    "print(\"Graph after: \", protein_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph before:  PackedProtein(batch_size=1, num_atoms=[2639], num_bonds=[5368], num_residues=[350])\n",
      "Graph after:  PackedProtein(batch_size=1, num_atoms=[350], num_bonds=[7276], num_residues=[350])\n",
      "Average degree:  tensor(41.5771)\n",
      "Maximum degree:  tensor(76.)\n",
      "Minimum degree:  tensor(12.)\n",
      "Number of zero-degree nodes:  tensor(0)\n"
     ]
    }
   ],
   "source": [
    "graph_construction_model = layers.GraphConstruction(node_layers=[geometry.AlphaCarbonNode()], \n",
    "                                                    edge_layers=[geometry.SpatialEdge(radius=10.0, min_distance=5),\n",
    "                                                                 geometry.KNNEdge(k=10, min_distance=5),\n",
    "                                                                 geometry.SequentialEdge(max_distance=2)])\n",
    "\n",
    "_protein = data.Protein.pack([protein])\n",
    "protein_ = graph_construction_model(_protein)\n",
    "print(\"Graph before: \", _protein)\n",
    "print(\"Graph after: \", protein_)\n",
    "\n",
    "degree = protein_.degree_in + protein_.degree_out\n",
    "print(\"Average degree: \", degree.mean())\n",
    "print(\"Maximum degree: \", degree.max())\n",
    "print(\"Minimum degree: \", degree.min())\n",
    "print(\"Number of zero-degree nodes: \", (degree == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug import models\n",
    "\n",
    "gearnet = models.GearNet(input_dim=21, hidden_dims=[512, 512, 512], num_relation=7,\n",
    "                         batch_norm=True, concat_hidden=True, short_cut=True, readout=\"sum\")\n",
    "gearnet_edge = models.GearNet(input_dim=21, hidden_dims=[512, 512, 512], \n",
    "                              num_relation=7, edge_input_dim=59, num_angle_bin=8,\n",
    "                              batch_norm=True, concat_hidden=True, short_cut=True, readout=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug import tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_construction_model = layers.GraphConstruction(node_layers=[geometry.AlphaCarbonNode()], \n",
    "                                                    edge_layers=[geometry.SpatialEdge(radius=10.0, min_distance=5),\n",
    "                                                                 geometry.KNNEdge(k=10, min_distance=5),\n",
    "                                                                 geometry.SequentialEdge(max_distance=2)],\n",
    "                                                    edge_feature=\"gearnet\")\n",
    "\n",
    "task = tasks.MultipleBinaryClassification(gearnet, graph_construction_model=graph_construction_model, num_mlp_layer=3,\n",
    "                                          task=[_ for _ in range(len(dataset.tasks))], criterion=\"bce\", metric=[\"auprc@micro\", \"f1_max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:37:52   Preprocess training set\n",
      "00:37:53   {'batch_size': 4,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': None,\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'capturable': False,\n",
      "               'class': 'optim.Adam',\n",
      "               'differentiable': False,\n",
      "               'eps': 1e-08,\n",
      "               'foreach': None,\n",
      "               'fused': False,\n",
      "               'lr': 0.0001,\n",
      "               'maximize': False,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'tasks.MultipleBinaryClassification',\n",
      "          'criterion': 'bce',\n",
      "          'graph_construction_model': {'class': 'layers.GraphConstruction',\n",
      "                                       'edge_feature': 'gearnet',\n",
      "                                       'edge_layers': [{'class': 'layers.geometry.SpatialEdge',\n",
      "                                                        'max_distance': None,\n",
      "                                                        'max_num_neighbors': 32,\n",
      "                                                        'min_distance': 5,\n",
      "                                                        'radius': 10.0},\n",
      "                                                       {'class': 'layers.geometry.KNNEdge',\n",
      "                                                        'k': 10,\n",
      "                                                        'max_distance': None,\n",
      "                                                        'min_distance': 5},\n",
      "                                                       {'class': 'layers.geometry.SequentialEdge',\n",
      "                                                        'max_distance': 2,\n",
      "                                                        'only_backbone': False}],\n",
      "                                       'node_layers': [{'class': 'layers.geometry.AlphaCarbonNode'}]},\n",
      "          'metric': ['auprc@micro', 'f1_max'],\n",
      "          'model': {'activation': 'relu',\n",
      "                    'batch_norm': True,\n",
      "                    'class': 'models.GearNet',\n",
      "                    'concat_hidden': True,\n",
      "                    'edge_input_dim': None,\n",
      "                    'hidden_dims': [512, 512, 512],\n",
      "                    'input_dim': 21,\n",
      "                    'num_angle_bin': None,\n",
      "                    'num_relation': 7,\n",
      "                    'readout': 'sum',\n",
      "                    'short_cut': True},\n",
      "          'normalization': True,\n",
      "          'num_mlp_layer': 3,\n",
      "          'reweight': False,\n",
      "          'task': [0, 1, 2, ..., 535, 536, 537],\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'datasets.EnzymeCommission',\n",
      "                          'path': '~/protein-datasets/',\n",
      "                          'test_cutoff': 0.95,\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [{'class': 'transforms.TruncateProtein',\n",
      "                                                        'keys': 'graph',\n",
      "                                                        'max_length': 350,\n",
      "                                                        'random': False},\n",
      "                                                       {'class': 'transforms.ProteinView',\n",
      "                                                        'keys': 'graph',\n",
      "                                                        'view': 'residue'}]},\n",
      "                          'verbose': 1},\n",
      "              'indices': range(1071, 1169)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.EnzymeCommission',\n",
      "                           'path': '~/protein-datasets/',\n",
      "                           'test_cutoff': 0.95,\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [{'class': 'transforms.TruncateProtein',\n",
      "                                                         'keys': 'graph',\n",
      "                                                         'max_length': 350,\n",
      "                                                         'random': False},\n",
      "                                                        {'class': 'transforms.ProteinView',\n",
      "                                                         'keys': 'graph',\n",
      "                                                         'view': 'residue'}]},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 974)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.EnzymeCommission',\n",
      "                           'path': '~/protein-datasets/',\n",
      "                           'test_cutoff': 0.95,\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [{'class': 'transforms.TruncateProtein',\n",
      "                                                         'keys': 'graph',\n",
      "                                                         'max_length': 350,\n",
      "                                                         'random': False},\n",
      "                                                        {'class': 'transforms.ProteinView',\n",
      "                                                         'keys': 'graph',\n",
      "                                                         'view': 'residue'}]},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(974, 1071)}}\n",
      "00:37:53   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "00:37:53   Epoch 0 begin\n",
      "torch.Size([1170, 1170, 7]) torch.Size([1170, 21])\n",
      "torch.Size([1170, 8190])\n",
      "7 21\n",
      "torch.Size([8190, 21])\n",
      "(tensor(1170), 147)\n",
      "torch.Size([1170, 1170, 7]) torch.Size([1170, 512])\n",
      "torch.Size([1170, 8190])\n",
      "7 512\n",
      "torch.Size([8190, 512])\n",
      "(tensor(1170), 3584)\n",
      "torch.Size([1170, 1170, 7]) torch.Size([1170, 512])\n",
      "torch.Size([1170, 8190])\n",
      "7 512\n",
      "torch.Size([8190, 512])\n",
      "(tensor(1170), 3584)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/harper.h/Documents/cs224w/final_project/GearNet/tutorial3.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harper.h/Documents/cs224w/final_project/GearNet/tutorial3.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(task\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harper.h/Documents/cs224w/final_project/GearNet/tutorial3.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m solver \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39mEngine(task, train_set, valid_set, test_set, optimizer,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harper.h/Documents/cs224w/final_project/GearNet/tutorial3.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                       batch_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/harper.h/Documents/cs224w/final_project/GearNet/tutorial3.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m solver\u001b[39m.\u001b[39;49mtrain(num_epoch\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/cs224w/project/.conda/lib/python3.10/site-packages/torchdrug/core/engine.py:161\u001b[0m, in \u001b[0;36mEngine.train\u001b[0;34m(self, num_epoch, batch_per_epoch)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    159\u001b[0m     batch \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mcuda(batch, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 161\u001b[0m loss, metric, _ \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m loss\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m    163\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLoss doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt require grad. Did you define any loss in the task?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "from torchdrug import core\n",
    "import torch\n",
    "\n",
    "optimizer = torch.optim.Adam(task.parameters(), lr=1e-4)\n",
    "solver = core.Engine(task, train_set, valid_set, test_set, optimizer,\n",
    "                      batch_size=4)\n",
    "solver.train(num_epoch=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:04:41   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "22:04:41   Evaluate on valid\n",
      "torch.Size([1209, 1209, 7]) torch.Size([1209, 21])\n",
      "torch.Size([1209, 8463])\n",
      "7 21\n",
      "torch.Size([8463, 21])\n",
      "(tensor(1209), 147)\n",
      "torch.Size([1209, 1209, 7]) torch.Size([1209, 512])\n",
      "torch.Size([1209, 8463])\n",
      "7 512\n",
      "torch.Size([8463, 512])\n",
      "(tensor(1209), 3584)\n",
      "torch.Size([1209, 1209, 7]) torch.Size([1209, 512])\n",
      "torch.Size([1209, 8463])\n",
      "7 512\n",
      "torch.Size([8463, 512])\n",
      "(tensor(1209), 3584)\n",
      "torch.Size([973, 973, 7]) torch.Size([973, 21])\n",
      "torch.Size([973, 6811])\n",
      "7 21\n",
      "torch.Size([6811, 21])\n",
      "(tensor(973), 147)\n",
      "torch.Size([973, 973, 7]) torch.Size([973, 512])\n",
      "torch.Size([973, 6811])\n",
      "7 512\n",
      "torch.Size([6811, 512])\n",
      "(tensor(973), 3584)\n",
      "torch.Size([973, 973, 7]) torch.Size([973, 512])\n",
      "torch.Size([973, 6811])\n",
      "7 512\n",
      "torch.Size([6811, 512])\n",
      "(tensor(973), 3584)\n",
      "torch.Size([797, 797, 7]) torch.Size([797, 21])\n",
      "torch.Size([797, 5579])\n",
      "7 21\n",
      "torch.Size([5579, 21])\n",
      "(tensor(797), 147)\n",
      "torch.Size([797, 797, 7]) torch.Size([797, 512])\n",
      "torch.Size([797, 5579])\n",
      "7 512\n",
      "torch.Size([5579, 512])\n",
      "(tensor(797), 3584)\n",
      "torch.Size([797, 797, 7]) torch.Size([797, 512])\n",
      "torch.Size([797, 5579])\n",
      "7 512\n",
      "torch.Size([5579, 512])\n",
      "(tensor(797), 3584)\n",
      "torch.Size([1400, 1400, 7]) torch.Size([1400, 21])\n",
      "torch.Size([1400, 9800])\n",
      "7 21\n",
      "torch.Size([9800, 21])\n",
      "(tensor(1400), 147)\n",
      "torch.Size([1400, 1400, 7]) torch.Size([1400, 512])\n",
      "torch.Size([1400, 9800])\n",
      "7 512\n",
      "torch.Size([9800, 512])\n",
      "(tensor(1400), 3584)\n",
      "torch.Size([1400, 1400, 7]) torch.Size([1400, 512])\n",
      "torch.Size([1400, 9800])\n",
      "7 512\n",
      "torch.Size([9800, 512])\n",
      "(tensor(1400), 3584)\n",
      "torch.Size([704, 704, 7]) torch.Size([704, 21])\n",
      "torch.Size([704, 4928])\n",
      "7 21\n",
      "torch.Size([4928, 21])\n",
      "(tensor(704), 147)\n",
      "torch.Size([704, 704, 7]) torch.Size([704, 512])\n",
      "torch.Size([704, 4928])\n",
      "7 512\n",
      "torch.Size([4928, 512])\n",
      "(tensor(704), 3584)\n",
      "torch.Size([704, 704, 7]) torch.Size([704, 512])\n",
      "torch.Size([704, 4928])\n",
      "7 512\n",
      "torch.Size([4928, 512])\n",
      "(tensor(704), 3584)\n",
      "torch.Size([1131, 1131, 7]) torch.Size([1131, 21])\n",
      "torch.Size([1131, 7917])\n",
      "7 21\n",
      "torch.Size([7917, 21])\n",
      "(tensor(1131), 147)\n",
      "torch.Size([1131, 1131, 7]) torch.Size([1131, 512])\n",
      "torch.Size([1131, 7917])\n",
      "7 512\n",
      "torch.Size([7917, 512])\n",
      "(tensor(1131), 3584)\n",
      "torch.Size([1131, 1131, 7]) torch.Size([1131, 512])\n",
      "torch.Size([1131, 7917])\n",
      "7 512\n",
      "torch.Size([7917, 512])\n",
      "(tensor(1131), 3584)\n",
      "torch.Size([707, 707, 7]) torch.Size([707, 21])\n",
      "torch.Size([707, 4949])\n",
      "7 21\n",
      "torch.Size([4949, 21])\n",
      "(tensor(707), 147)\n",
      "torch.Size([707, 707, 7]) torch.Size([707, 512])\n",
      "torch.Size([707, 4949])\n",
      "7 512\n",
      "torch.Size([4949, 512])\n",
      "(tensor(707), 3584)\n",
      "torch.Size([707, 707, 7]) torch.Size([707, 512])\n",
      "torch.Size([707, 4949])\n",
      "7 512\n",
      "torch.Size([4949, 512])\n",
      "(tensor(707), 3584)\n",
      "torch.Size([844, 844, 7]) torch.Size([844, 21])\n",
      "torch.Size([844, 5908])\n",
      "7 21\n",
      "torch.Size([5908, 21])\n",
      "(tensor(844), 147)\n",
      "torch.Size([844, 844, 7]) torch.Size([844, 512])\n",
      "torch.Size([844, 5908])\n",
      "7 512\n",
      "torch.Size([5908, 512])\n",
      "(tensor(844), 3584)\n",
      "torch.Size([844, 844, 7]) torch.Size([844, 512])\n",
      "torch.Size([844, 5908])\n",
      "7 512\n",
      "torch.Size([5908, 512])\n",
      "(tensor(844), 3584)\n",
      "torch.Size([1101, 1101, 7]) torch.Size([1101, 21])\n",
      "torch.Size([1101, 7707])\n",
      "7 21\n",
      "torch.Size([7707, 21])\n",
      "(tensor(1101), 147)\n",
      "torch.Size([1101, 1101, 7]) torch.Size([1101, 512])\n",
      "torch.Size([1101, 7707])\n",
      "7 512\n",
      "torch.Size([7707, 512])\n",
      "(tensor(1101), 3584)\n",
      "torch.Size([1101, 1101, 7]) torch.Size([1101, 512])\n",
      "torch.Size([1101, 7707])\n",
      "7 512\n",
      "torch.Size([7707, 512])\n",
      "(tensor(1101), 3584)\n",
      "torch.Size([1017, 1017, 7]) torch.Size([1017, 21])\n",
      "torch.Size([1017, 7119])\n",
      "7 21\n",
      "torch.Size([7119, 21])\n",
      "(tensor(1017), 147)\n",
      "torch.Size([1017, 1017, 7]) torch.Size([1017, 512])\n",
      "torch.Size([1017, 7119])\n",
      "7 512\n",
      "torch.Size([7119, 512])\n",
      "(tensor(1017), 3584)\n",
      "torch.Size([1017, 1017, 7]) torch.Size([1017, 512])\n",
      "torch.Size([1017, 7119])\n",
      "7 512\n",
      "torch.Size([7119, 512])\n",
      "(tensor(1017), 3584)\n",
      "torch.Size([944, 944, 7]) torch.Size([944, 21])\n",
      "torch.Size([944, 6608])\n",
      "7 21\n",
      "torch.Size([6608, 21])\n",
      "(tensor(944), 147)\n",
      "torch.Size([944, 944, 7]) torch.Size([944, 512])\n",
      "torch.Size([944, 6608])\n",
      "7 512\n",
      "torch.Size([6608, 512])\n",
      "(tensor(944), 3584)\n",
      "torch.Size([944, 944, 7]) torch.Size([944, 512])\n",
      "torch.Size([944, 6608])\n",
      "7 512\n",
      "torch.Size([6608, 512])\n",
      "(tensor(944), 3584)\n",
      "torch.Size([1034, 1034, 7]) torch.Size([1034, 21])\n",
      "torch.Size([1034, 7238])\n",
      "7 21\n",
      "torch.Size([7238, 21])\n",
      "(tensor(1034), 147)\n",
      "torch.Size([1034, 1034, 7]) torch.Size([1034, 512])\n",
      "torch.Size([1034, 7238])\n",
      "7 512\n",
      "torch.Size([7238, 512])\n",
      "(tensor(1034), 3584)\n",
      "torch.Size([1034, 1034, 7]) torch.Size([1034, 512])\n",
      "torch.Size([1034, 7238])\n",
      "7 512\n",
      "torch.Size([7238, 512])\n",
      "(tensor(1034), 3584)\n",
      "torch.Size([1067, 1067, 7]) torch.Size([1067, 21])\n",
      "torch.Size([1067, 7469])\n",
      "7 21\n",
      "torch.Size([7469, 21])\n",
      "(tensor(1067), 147)\n",
      "torch.Size([1067, 1067, 7]) torch.Size([1067, 512])\n",
      "torch.Size([1067, 7469])\n",
      "7 512\n",
      "torch.Size([7469, 512])\n",
      "(tensor(1067), 3584)\n",
      "torch.Size([1067, 1067, 7]) torch.Size([1067, 512])\n",
      "torch.Size([1067, 7469])\n",
      "7 512\n",
      "torch.Size([7469, 512])\n",
      "(tensor(1067), 3584)\n",
      "torch.Size([1083, 1083, 7]) torch.Size([1083, 21])\n",
      "torch.Size([1083, 7581])\n",
      "7 21\n",
      "torch.Size([7581, 21])\n",
      "(tensor(1083), 147)\n",
      "torch.Size([1083, 1083, 7]) torch.Size([1083, 512])\n",
      "torch.Size([1083, 7581])\n",
      "7 512\n",
      "torch.Size([7581, 512])\n",
      "(tensor(1083), 3584)\n",
      "torch.Size([1083, 1083, 7]) torch.Size([1083, 512])\n",
      "torch.Size([1083, 7581])\n",
      "7 512\n",
      "torch.Size([7581, 512])\n",
      "(tensor(1083), 3584)\n",
      "torch.Size([593, 593, 7]) torch.Size([593, 21])\n",
      "torch.Size([593, 4151])\n",
      "7 21\n",
      "torch.Size([4151, 21])\n",
      "(tensor(593), 147)\n",
      "torch.Size([593, 593, 7]) torch.Size([593, 512])\n",
      "torch.Size([593, 4151])\n",
      "7 512\n",
      "torch.Size([4151, 512])\n",
      "(tensor(593), 3584)\n",
      "torch.Size([593, 593, 7]) torch.Size([593, 512])\n",
      "torch.Size([593, 4151])\n",
      "7 512\n",
      "torch.Size([4151, 512])\n",
      "(tensor(593), 3584)\n",
      "torch.Size([1200, 1200, 7]) torch.Size([1200, 21])\n",
      "torch.Size([1200, 8400])\n",
      "7 21\n",
      "torch.Size([8400, 21])\n",
      "(tensor(1200), 147)\n",
      "torch.Size([1200, 1200, 7]) torch.Size([1200, 512])\n",
      "torch.Size([1200, 8400])\n",
      "7 512\n",
      "torch.Size([8400, 512])\n",
      "(tensor(1200), 3584)\n",
      "torch.Size([1200, 1200, 7]) torch.Size([1200, 512])\n",
      "torch.Size([1200, 8400])\n",
      "7 512\n",
      "torch.Size([8400, 512])\n",
      "(tensor(1200), 3584)\n",
      "torch.Size([834, 834, 7]) torch.Size([834, 21])\n",
      "torch.Size([834, 5838])\n",
      "7 21\n",
      "torch.Size([5838, 21])\n",
      "(tensor(834), 147)\n",
      "torch.Size([834, 834, 7]) torch.Size([834, 512])\n",
      "torch.Size([834, 5838])\n",
      "7 512\n",
      "torch.Size([5838, 512])\n",
      "(tensor(834), 3584)\n",
      "torch.Size([834, 834, 7]) torch.Size([834, 512])\n",
      "torch.Size([834, 5838])\n",
      "7 512\n",
      "torch.Size([5838, 512])\n",
      "(tensor(834), 3584)\n",
      "torch.Size([769, 769, 7]) torch.Size([769, 21])\n",
      "torch.Size([769, 5383])\n",
      "7 21\n",
      "torch.Size([5383, 21])\n",
      "(tensor(769), 147)\n",
      "torch.Size([769, 769, 7]) torch.Size([769, 512])\n",
      "torch.Size([769, 5383])\n",
      "7 512\n",
      "torch.Size([5383, 512])\n",
      "(tensor(769), 3584)\n",
      "torch.Size([769, 769, 7]) torch.Size([769, 512])\n",
      "torch.Size([769, 5383])\n",
      "7 512\n",
      "torch.Size([5383, 512])\n",
      "(tensor(769), 3584)\n",
      "torch.Size([1055, 1055, 7]) torch.Size([1055, 21])\n",
      "torch.Size([1055, 7385])\n",
      "7 21\n",
      "torch.Size([7385, 21])\n",
      "(tensor(1055), 147)\n",
      "torch.Size([1055, 1055, 7]) torch.Size([1055, 512])\n",
      "torch.Size([1055, 7385])\n",
      "7 512\n",
      "torch.Size([7385, 512])\n",
      "(tensor(1055), 3584)\n",
      "torch.Size([1055, 1055, 7]) torch.Size([1055, 512])\n",
      "torch.Size([1055, 7385])\n",
      "7 512\n",
      "torch.Size([7385, 512])\n",
      "(tensor(1055), 3584)\n",
      "torch.Size([1090, 1090, 7]) torch.Size([1090, 21])\n",
      "torch.Size([1090, 7630])\n",
      "7 21\n",
      "torch.Size([7630, 21])\n",
      "(tensor(1090), 147)\n",
      "torch.Size([1090, 1090, 7]) torch.Size([1090, 512])\n",
      "torch.Size([1090, 7630])\n",
      "7 512\n",
      "torch.Size([7630, 512])\n",
      "(tensor(1090), 3584)\n",
      "torch.Size([1090, 1090, 7]) torch.Size([1090, 512])\n",
      "torch.Size([1090, 7630])\n",
      "7 512\n",
      "torch.Size([7630, 512])\n",
      "(tensor(1090), 3584)\n",
      "torch.Size([999, 999, 7]) torch.Size([999, 21])\n",
      "torch.Size([999, 6993])\n",
      "7 21\n",
      "torch.Size([6993, 21])\n",
      "(tensor(999), 147)\n",
      "torch.Size([999, 999, 7]) torch.Size([999, 512])\n",
      "torch.Size([999, 6993])\n",
      "7 512\n",
      "torch.Size([6993, 512])\n",
      "(tensor(999), 3584)\n",
      "torch.Size([999, 999, 7]) torch.Size([999, 512])\n",
      "torch.Size([999, 6993])\n",
      "7 512\n",
      "torch.Size([6993, 512])\n",
      "(tensor(999), 3584)\n",
      "torch.Size([1119, 1119, 7]) torch.Size([1119, 21])\n",
      "torch.Size([1119, 7833])\n",
      "7 21\n",
      "torch.Size([7833, 21])\n",
      "(tensor(1119), 147)\n",
      "torch.Size([1119, 1119, 7]) torch.Size([1119, 512])\n",
      "torch.Size([1119, 7833])\n",
      "7 512\n",
      "torch.Size([7833, 512])\n",
      "(tensor(1119), 3584)\n",
      "torch.Size([1119, 1119, 7]) torch.Size([1119, 512])\n",
      "torch.Size([1119, 7833])\n",
      "7 512\n",
      "torch.Size([7833, 512])\n",
      "(tensor(1119), 3584)\n",
      "torch.Size([831, 831, 7]) torch.Size([831, 21])\n",
      "torch.Size([831, 5817])\n",
      "7 21\n",
      "torch.Size([5817, 21])\n",
      "(tensor(831), 147)\n",
      "torch.Size([831, 831, 7]) torch.Size([831, 512])\n",
      "torch.Size([831, 5817])\n",
      "7 512\n",
      "torch.Size([5817, 512])\n",
      "(tensor(831), 3584)\n",
      "torch.Size([831, 831, 7]) torch.Size([831, 512])\n",
      "torch.Size([831, 5817])\n",
      "7 512\n",
      "torch.Size([5817, 512])\n",
      "(tensor(831), 3584)\n",
      "torch.Size([823, 823, 7]) torch.Size([823, 21])\n",
      "torch.Size([823, 5761])\n",
      "7 21\n",
      "torch.Size([5761, 21])\n",
      "(tensor(823), 147)\n",
      "torch.Size([823, 823, 7]) torch.Size([823, 512])\n",
      "torch.Size([823, 5761])\n",
      "7 512\n",
      "torch.Size([5761, 512])\n",
      "(tensor(823), 3584)\n",
      "torch.Size([823, 823, 7]) torch.Size([823, 512])\n",
      "torch.Size([823, 5761])\n",
      "7 512\n",
      "torch.Size([5761, 512])\n",
      "(tensor(823), 3584)\n",
      "torch.Size([168, 168, 7]) torch.Size([168, 21])\n",
      "torch.Size([168, 1176])\n",
      "7 21\n",
      "torch.Size([1176, 21])\n",
      "(tensor(168), 147)\n",
      "torch.Size([168, 168, 7]) torch.Size([168, 512])\n",
      "torch.Size([168, 1176])\n",
      "7 512\n",
      "torch.Size([1176, 512])\n",
      "(tensor(168), 3584)\n",
      "torch.Size([168, 168, 7]) torch.Size([168, 512])\n",
      "torch.Size([168, 1176])\n",
      "7 512\n",
      "torch.Size([1176, 512])\n",
      "(tensor(168), 3584)\n",
      "22:04:42   ------------------------------\n",
      "22:04:42   auprc@micro: 0.188562\n",
      "22:04:42   f1_max: 0.269671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auprc@micro': tensor(0.1886), 'f1_max': tensor(0.2697)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.evaluate(\"valid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
